# 模型性能对比

| 模型名称 | 备注/描述 | 平均准确率 | 最佳准确率 | 第1轮 | 第2轮 | 第3轮 | 第4轮 | 第5轮 | 第6轮 | 第7轮 | 第8轮 | 第9轮 | 第10轮 |
|----------|-----------|------------|------------|-------|-------|-------|-------|-------|-------|-------|-------|-------|--------|
| TextCNN | 基于GloVe的CNN文本分类 | 0.7066 | 0.8095 | 0.5852 | 0.5663 | 0.6135 | 0.6048 | 0.7813 | 0.7799 | 0.7842 | 0.8095 | 0.7573 | 0.7842 |
| LSTM | 基于GloVe的LSTM文本分类 | 0.788 | 0.83 | 0.69 | 0.79 | 0.8 | 0.82 | 0.83 | 0.79 | 0.78 | 0.75 | 0.8 | 0.81 |
| CNN-LSTM | 基于GloVe的CNN-LSTM文本分类 | 0.7674 | 0.8784 | 0.5688 | 0.6116 | 0.6048 | 0.7601 | 0.7996 | 0.8562 | 0.8667 | 0.8784 | 0.8519 | 0.8762 |
| Capsule-LSTM | 基于GloVe的Capsule-LSTM文本分类 | 0.511 | 0.511 | 0.49 | 0.49 | 0.49 | 0.49 | 0.51 | 0.49 | 0.49 | 0.51 | 0.51 | 0.51 |
| Attention-LSTM | 注意力机制LSTM文本分类 | 0.856 | 0.87 | 0.82 | 0.85 | 0.85 | 0.84 | 0.85 | 0.87 | 0.87 | 0.87 | 0.87 | 0.87 |
| BERT | BERT-base-uncased文本分类 | 0.9167 | 0.92 | 0.89 | 0.92 | 0.96 | | | | | | | |
| BERT_scratch | 自定义BERT分类器 | 0.9293 | 0.9324 | 0.924 | 0.9322 | 0.9324 | | | | | | | |
| BERT_trainer | HuggingFace Trainer训练BERT | 0.9307 | 0.9398 | 0.9234 | 0.9288 | 0.9398 | | | | | | | |
| GRU | Glove+GRU情感分类 | 0.813 | 0.88 | 0.64 | 0.78 | 0.82 | 0.83 | 0.86 | 0.84 | 0.87 | 0.88 | 0.81 | 0.8 |
| DistilBERT_native | 轻量级BERT蒸馏模型 | 0.9167 | 0.92 | 0.91 | 0.92 | 0.92 | | | | | | | |
| DistilBERT_Trainer | 轻量级蒸馏模型，使用Trainer训练3轮 | 0.9289 | 0.9344 | 0.9186 | 0.9338 | 0.9344 | | | | | | | |
| RoBERTa_trainer | 使用Trainer训练3轮 | 0.9379 | 0.9448 | 0.9256 | 0.9432 | 0.9448 | | | | | | | |
| Transformer | 基于Transformer的文本分类 | 0.683 | 0.73 | 0.71 | 0.71 | 0.72 | 0.64 | 0.66 | 0.53 | 0.71 | 0.73 | 0.71 | 0.71 |
